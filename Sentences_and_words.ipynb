{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following two cells first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import csv\n",
    "import tarfile\n",
    "import string\n",
    "from collections import Counter\n",
    "from nltk import RegexpTokenizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1) # To display full content of the column\n",
    "# pd.set_option('display.max_rows', None) # To display ALL rows of the dataframe (otherwise you can decide the max number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read sentences (do this first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading all sentences takes a long time so let's split the process into two steps. You only need to run the two following cells once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat sentences_detailed.tar.bz2.part* > sentences_detailed.tar.bz2\n",
    "def read_sentences_file():\n",
    "    with tarfile.open('./sentences_detailed.tar.bz2', 'r:*') as tar:\n",
    "        csv_path = tar.getnames()[0]\n",
    "        return pd.read_csv(tar.extractfile(csv_path), \n",
    "                sep='\\t', \n",
    "                header=None, \n",
    "                names=['sentenceID', 'ISO', 'Text', 'Username', 'Date added', 'Date last modified'],\n",
    "                quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = read_sentences_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can fetch sentences of a specific language using the following cells. When you want to change you target language, you can start again from here.\n",
    "\n",
    "Note that by default, we get rid of the `ISO`, `Date added`, `Date last modified`, and `Username` columns.  \n",
    "If you need any of these columns, you can comment the lines you need by adding a `#` at the beginning of the corresponding lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_of_language(sentences, language):\n",
    "    target_sentences = sentences[sentences['ISO'] == language]\n",
    "    del target_sentences['Date added']\n",
    "    del target_sentences['Date last modified']\n",
    "    del target_sentences['ISO']\n",
    "    del target_sentences['Username']\n",
    "    target_sentences = target_sentences.set_index(\"sentenceID\")\n",
    "    return target_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose your target language as a 3-letter ISO code (`cmn`, `fra`, `jpn`, `eng`, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'fra'\n",
    "sentences = sentences_of_language(all_sentences, language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell displays the first five sentences of your set, just for a quick check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To only get the text of sentence with a specific id, use the following syntax `sentences.loc[<sentenceID>].Text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences.loc[1115].Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentences containing a specific word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(word, sentences):\n",
    "    frame = sentences[sentences['Text'].str.contains(word)]\n",
    "    frame = frame.append(sentences[sentences['Text'].str.contains(word.capitalize())])\n",
    "    frame = frame.append(sentences[sentences['Text'].str.contains(word.upper())])\n",
    "    frame = frame.append(sentences[sentences['Text'].str.contains(word.lower())])\n",
    "    frame.drop_duplicates()\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the word you want to search, run the cell, and all sentences (from your sentences set) containing your word will be displayed.  \n",
    "The occurences that will match are your word, and your word in lowercase, uppercase, or capitalized.  \n",
    "For example, if you look for `beauty`, sentences starting by `Beauty` will also match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word = \"skis\"\n",
    "get_sentences(word, sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to check (some of) the sentences containing one word exactly (that is, the case is matching), you can use the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"exemple\"\n",
    "sentences[sentences['Text'].str.contains(word)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking how many sentences for a list of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that you want to check how many sentences contain a specific word. You could use `get_sentences` above and count the results. However, if you have several words in mind, and you only want to know how many sentences contain them, you can use the following.\n",
    "\n",
    "/!\\ Currently, only sentences matching **exactly** your word will be counted (no uppercase, no capitalization, etc.) /!\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_many_sentences(word_list, sentences):\n",
    "    for w in word_list:\n",
    "        print(w + \"\\t\\t\" + str(len(sentences[sentences['Text'].str.contains(w)])))\n",
    "#         if len(sentences[sentences['Text'].str.contains(w)]) <= 10:\n",
    "#             print(w + \"\\t\\t\" + str(len(sentences[sentences['Text'].str.contains(w)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, replace `word_list` by the words you are interested in.  \n",
    "Do not forget the brackets and the quotes. `word_list` format should be `word_list = [\"word1\", \"word2\", ..., \"wordn\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [\"manger\", \"skis\", \"mirage\", \"oasis\"]\n",
    "how_many_sentences(word_list, sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, suppose that you only want to check the words from your list who appears in less than `n` sentences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_many_sentences_under_threshold(word_list, threshold, sentences):\n",
    "    for w in word_list:\n",
    "        nb_occurences = len(sentences[sentences['Text'].str.contains(w)])\n",
    "        if nb_occurences <= threshold:\n",
    "            print(w + \"\\t\\t\" + str(nb_occurences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your own list of words, as specified above and set `n` to the number of sentences you want to set as a threshold.  \n",
    "For example, if `n` is set to 10, only words that appear in less than 10 sentences will return, along with the number of sentences in which they appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [\"manger\", \"skis\", \"mirage\", \"oasis\"]\n",
    "n = 10\n",
    "how_many_sentences_under_threshold(word_list, n, sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some standard symbols to ignore are given by the following cell.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should add punctuation specific to your target language to `additional_punctuation` below (respect the format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_punctuation = ['``', \"''\", '``', \"''\", '...', '’', '``', \"''\", '«', '»',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will dispay a list of what will be consider \"useless\" words. Those are common [stop words](https://en.wikipedia.org/wiki/Stop_words) PLUS all the punctuation symbols defined above.  \n",
    "If you're note happy with this list, you can limit it to only punctuation by removing `nltk.corpus.stopwords.words()`, or extend it by adding another list to `useless_words`\n",
    "\n",
    "This list of stop words use the `stopwords` corpus of the nltk package. Note that a limited number of languages are available. Currently availabe are  \n",
    "`arabic`, `azerbaijani`, `danish`, `dutch`, `english`, `finnish`, `french`, `german`, `greek`, `hungarian`, `indonesion`, `italian`, `kazakh`, `nepali`, `norwegian`, `portuguese`, `romanian`, `russian`, `slovene`, `spanish`, `swedish`, `tajik`, `turkish`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"french\"\n",
    "useless_words = nltk.corpus.stopwords.words(language) + list(string.punctuation) + additional_punctuation\n",
    "useless_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of words in fra_sentences['Text']\n",
    "texts = [word for word in sentences['Text']]\n",
    "all_words = [word for text in texts for word in nltk.word_tokenize(text)]\n",
    "# \"Raw\" number of words\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a RegexpTokenizer to improve tokenizing of French sentences.\n",
    "# We want to split at apostrophes.\n",
    "toknizer = RegexpTokenizer(r\"''\\w'|\\w+|[^\\w\\s]''\")\n",
    "filtered_words = [word.lower() for text in texts for word in toknizer.tokenize(text) if not word.lower() in useless_words]\n",
    "# Filter numbers written with digits\n",
    "filtered_words = [word for word in filtered_words if not word.isdigit()]\n",
    "# Number of filtered words\n",
    "len(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique words\n",
    "len(set(filtered_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter = Counter(filtered_words)\n",
    "most_common_words = word_counter.most_common()\n",
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "sorted_word_counts = sorted(list(word_counter.values()), reverse=True)\n",
    "\n",
    "plt.loglog(sorted_word_counts)\n",
    "plt.ylabel(\"Freq\")\n",
    "plt.xlabel(\"Word Rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(word_counter, orient='index')\n",
    "df = df.rename(columns={'index':'word', 0:'count'})\n",
    "df = df.sort_values(by='count', ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words that appear only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_words = df[df['count'] == 1]\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `df.head(n)` for the `n` most used words.  \n",
    "Use `df.tail(n)` for `n` of the less used words.  \n",
    "You can use `df[m:n]` for the words between the m-th and n-th most used.\n",
    "\n",
    "For example, you can use this to go through words that are used only once to quickly find typos or erroneous words. First check the words that are used only once by `df.tail(n)`, then use `sentences[sentences['Text'].str.contains(word)]` with the words you fetched. That way, you can quickly check the sentence containing that word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First ten elements\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From 11th to 20th\n",
    "df[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last ten elements\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From 15th to the last until 10th to the last\n",
    "df[len(df)-15:len(df)-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.head()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[t[0] for t in most_common_words[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following display the 15 less used words along with the sentences that contain them. Notice however that it is a simplistic approach that may not exactly return what you want. If the word is `cat`, this will return `Cat`, `cats`, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15\n",
    "check_list = [t[0] for t in most_common_words[len(df)-n:len(df)]]\n",
    "for word in check_list:\n",
    "    print(word)\n",
    "    display(get_sentences(word, sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
